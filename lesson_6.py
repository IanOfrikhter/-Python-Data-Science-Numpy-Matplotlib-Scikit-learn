# -*- coding: utf-8 -*-
"""Lesson_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pb6gJQF3Vjkeh9jVH2eTpBCcyMp5dQSR

#Тема “Обучение с учителем”

##Задание 1

Импортируйте библиотеки pandas и numpy.
Загрузите "Boston House Prices dataset" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.
Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки
составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.
Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.
Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.
Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.
"""

import pandas as pd
import numpy as np

from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

boston = load_boston()
data = boston["data"]
feature_names = boston["feature_names"]

X_full = pd.DataFrame(data, columns=feature_names)
X_full.head()

target = boston["target"]

Y_full = pd.DataFrame(target, columns=["price"])
Y_full.head()

X_train, X_test, Y_train, Y_test = train_test_split(X_full, Y_full, test_size=0.30, random_state=42)

lr = LinearRegression()
lr.fit(X_train, Y_train)

y_pred_lr = lr.predict(X_test)
check_test_lr = pd.DataFrame({
    "Y_test": Y_test["price"], 
    "Y_pred_lr": y_pred_lr.flatten()})

check_test_lr.head()

mean_squared_error_lr = mean_squared_error(check_test_lr["Y_pred_lr"], check_test_lr["Y_test"])
print(mean_squared_error_lr)

r2_score_1=r2_score(check_test_lr["Y_pred_lr"], check_test_lr["Y_test"])
r2_score_1

"""##Задание 2

Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.
Сделайте агрумент n_estimators равным 1000,
max_depth должен быть равен 12 и random_state сделайте равным 42.
Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,
но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],
чтобы получить из датафрейма одномерный массив Numpy,
так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.
Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.
Напишите в комментариях к коду, какая модель в данном случае работает лучше.
"""

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)
model.fit(X_train, Y_train.values[:, 0])

Y_pred = model.predict(X_test)
Y_pred.shape

r2_score_2=r2_score(Y_pred, check_test_lr["Y_test"])
r2_score_2

print('r2 для модели линейной регрессии-', r2_score_1)
print('r2 для модели randomforest-', r2_score_2)

"""Вывод. Модель randomforest показывает лучшие результаты"""